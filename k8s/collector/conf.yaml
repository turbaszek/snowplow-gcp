kind: ConfigMap
metadata:
  name: collector-config
apiVersion: v1
data:
  production.conf: |-
      collector {
        # The collector runs as a web service specified on the following interface and port.
        interface = "0.0.0.0"
        port = 8080

        # The collector responds with a cookie to requests with a path that matches the 'vendor/version' protocol.
        # The expected values are:
        # - com.snowplowanalytics.snowplow/tp2 for Tracker Protocol 2
        # - r/tp2 for redirects
        # - com.snowplowanalytics.iglu/v1 for the Iglu Webhook
        # Any path that matches the 'vendor/version' protocol will result in a cookie response, for use by custom webhooks
        # downstream of the collector.
        # But you can also map any valid (i.e. two-segment) path to one of the three defaults.
        # Your custom path must be the key and the value must be one of the corresponding default paths. Both must be full
        # valid paths starting with a leading slash.
        # Pass in an empty map to avoid mapping.
        paths {
          # "/com.acme/track" = "/com.snowplowanalytics.snowplow/tp2"
          # "/com.acme/redirect" = "/r/tp2"
          # "/com.acme/iglu" = "/com.snowplowanalytics.iglu/v1"
        }

        # Configure the P3P policy header.
        p3p {
          policyRef = "/w3c/p3p.xml"
          CP = "NOI DSP COR NID PSA OUR IND COM NAV STA"
        }
        # Cross domain policy configuration.
        # If "enabled" is set to "false", the collector will respond with a 404 to the /crossdomain.xml
        # route.
        crossDomain {
          enabled = false
          # Domains that are granted access, *.acme.com will match http://acme.com and http://sub.acme.com
          domains = [ "*" ]
          # Whether to only grant access to HTTPS or both HTTPS and HTTP sources
          secure = true
        }
        # The collector returns a cookie to clients for user identification
        # with the following domain and expiration.
        cookie {
          enabled = true
          expiration = "365 days"
          # Network cookie name
          name = snowplow
          # The domain is optional and will make the cookie accessible to other
          # applications on the domain. Comment out this line to tie cookies to
          # the collector's full domain
          # domain = "{{cookieDomain}}"
          secure = false
          httpOnly = false
        }
        # If you have a do not track cookie in place, the Scala Stream Collector can respect it by
        # completely bypassing the processing of an incoming request carrying this cookie, the collector
        # will simply reply by a 200 saying "do not track".
        # The cookie name and value must match the configuration below.
        doNotTrackCookie {
          enabled = false
          name = snowplow_do_not_track
          value = snowplow_do_not_track_value
        }
        # When enabled and the cookie specified above is missing, performs a redirect to itself to check
        # if third-party cookies are blocked using the specified name. If they are indeed blocked,
        # fallbackNetworkId is used instead of generating a new random one.
        cookieBounce {
          enabled = false
          # The name of the request parameter which will be used on redirects checking that third-party
          # cookies work.
          name = "n3pc"
          # Network user id to fallback to when third-party cookies are blocked.
          fallbackNetworkUserId = "00000000-0000-4000-A000-000000000000"
          # Optionally, specify the name of the header containing the originating protocol for use in the
          # bounce redirect location. Use this if behind a load balancer that performs SSL termination.
          # The value of this header must be http or https. Example, if behind an AWS Classic ELB.
          forwardedProtocolHeader = "X-Forwarded-Proto"
        }
        # When enabled, the redirect url passed via the `u` query parameter is scanned for a placeholder
        # token. All instances of that token are replaced withe the network ID. If the placeholder isn't
        # specified, the default value is `${SP_NUID}`.
        redirectMacro {
          enabled = false
          # Optional custom placeholder token (defaults to the literal `${SP_NUID}`)
          # placeholder = "[TOKEN]"
        }
        # Customize response handling for requests for the root path ("/").
        # Useful if you need to redirect to web content or privacy policies regarding the use of this collector.
        rootResponse {
          enabled = false
          statusCode = 302
          # Optional, defaults to empty map
          headers = {
              Location = "https://127.0.0.1/",
              X-Custom = "something"
          }
          # Optional, defaults to empty string
          body = "302, redirecting"
        }

        # Configuration related to CORS preflight requests
        cors {
          # The Access-Control-Max-Age response header indicates how long the results of a preflight
          # request can be cached. -1 seconds disables the cache. Chromium max is 10m, Firefox is 24h.
          accessControlMaxAge = 5 seconds
        }

        # Configuration of prometheus http metrics
        prometheusMetrics {
          # If metrics are enabled then all requests will be logged as prometheus metrics
          # and '/metrics' endpoint will return the report about the requests
          enabled = false
          # Custom buckets for http_request_duration_seconds_bucket duration metric
          #durationBucketsInSeconds = [0.1, 3, 10]
        }

        streams {
          # Events which have successfully been collected will be stored in the good stream/topic
          good = good
          # Events that are too big (w.r.t Kinesis 1MB limit) will be stored in the bad stream/topic
          bad = bad
          # Whether to use the incoming event's ip as the partition key for the good stream/topic
          # Note: Nsq does not make use of partition key.
          useIpAddressAsPartitionKey = false
          # Enable the chosen sink by uncommenting the appropriate configuration
          sink {
            # Choose between kinesis, google-pub-sub, kafka, nsq, or stdout.
            # To use stdout, comment or remove everything in the "collector.streams.sink" section except
            # "enabled" which should be set to "stdout".
            enabled = google-pub-sub

            # Or Google Pubsub
            googleProjectId = your-project
            ## Minimum, maximum and total backoff periods, in milliseconds
            ## and multiplier between two backoff
            backoffPolicy {
              minBackoff = 100
              maxBackoff = 1000
              totalBackoff = 10000
              multiplier = 1.1
            }
          }
          # Incoming events are stored in a buffer before being sent to Kinesis/Kafka.
          # Note: Buffering is not supported by NSQ.
          # The buffer is emptied whenever:
          # - the number of stored records reaches record-limit or
          # - the combined size of the stored records reaches byte-limit or
          # - the time in milliseconds since the buffer was last emptied reaches time-limit
          buffer {
            byteLimit = 1000000
            recordLimit = 10
            timeLimit = 1000
          }
        }
      }
      # Akka has a variety of possible configuration options defined at
      # http://doc.akka.io/docs/akka/current/scala/general/configuration.html
      akka {
        loglevel = DEBUG # 'OFF' for no logging, 'DEBUG' for all logging.
        loggers = ["akka.event.slf4j.Slf4jLogger"]
        # akka-http is the server the Stream collector uses and has configurable options defined at
        # http://doc.akka.io/docs/akka-http/current/scala/http/configuration.html
        http.server {
          # To obtain the hostname in the collector, the 'remote-address' header
          # should be set. By default, this is disabled, and enabling it
          # adds the 'Remote-Address' header to every request automatically.
          remote-address-header = on
          raw-request-uri-header = on
          # Define the maximum request length (the default is 2048)
          parsing {
            max-uri-length = 32768
            uri-parsing-mode = relaxed
          }
        }
      }
